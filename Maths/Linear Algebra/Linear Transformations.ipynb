{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614a02c2-68cb-495e-8a0a-8d7e1085205a",
   "metadata": {},
   "source": [
    "#### Vector\n",
    "\n",
    "A vector is a point in n-dimensional space, each dimension is represented by a number.  \n",
    "\n",
    "2-dimension : $ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $  \n",
    "3-dimension : $ \\begin{bmatrix} 1 \\\\ 2 \\\\ 3\\end{bmatrix} $  \n",
    "\n",
    "A vector can also be thought of a state in n-dimensional space. Say, if I have two dimensions, apples and oranges that I have. $ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $ is a state where I have 1 apple and 2 oranges.  \n",
    "$ \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} $ is a state where I have 3 cycles, 2 scooters and 1 car.  \n",
    "\n",
    "#### Vector addition and subtraction\n",
    "\n",
    "I can reach to one state from another state by adding(or subtracting) another state. If I have 2 apples and 3 oranges, but I want 3 apples and 5 oranges, I need to have 1 apple and 2 oranges more to reach the desired state. In terms of vector addition it is :  \n",
    "\n",
    "$ \\begin{bmatrix} 2 \\\\ 3  \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 5 \\end{bmatrix} $  \n",
    "\n",
    "Note each dimension is added only to a similar dimension in another vector.  \n",
    "\n",
    "#### Linear transformation\n",
    "\n",
    "transformation: consider a rubber square(which is also a parallelogram) in first quadrant enclosed by basis vectors along x and y axis. The complete co-ordinate system can be considered as the repeatition of these squares along x and y axes. Any vector with natural numbers $ \\begin{bmatrix} a \\\\ b \\end{bmatrix} $  now can be represented by putting 'a' squares along x axis and then repeating these rectangle 'b' times along y axis, forming a rectangle of length 'a' and width 'b'. The vector is the diagonal of this rectangle starting from the center. This way we can represent any vector with natural numbers.  \n",
    "\n",
    "Imagine the diagonal represented by the vector $ \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} $ colored on the rectangle rubber (formed by 3x4=12 squares joined together) in black and each square colored in green. This diagonal is 3 squares away from y-axis and 4 squares away from x-axis.  \n",
    "\n",
    "![image info](vector34.png)\n",
    "\n",
    "Now let's apply any linear transformation on the rubber square starting at the center and located completely in the first quadrant, we can rotate the rubber square, we can stretch it to form a rectangle or stretch it such a way that it becomes a parallelogram. Just by definition of linear transformstion, the opposite side of the square should always remain parallel to each other and the corner of the square located at the center of the system should remain there.  \n",
    "\n",
    "Now, if we apply any transformation on all the 12 squares joined together (along with the one having the center as the corner) forming a 3x4 rectangle, it would become a larger parallelogram consisting of 12 same sized small parallelograms. If we had painted the diagonal of original 3x4 rectangle, it would still remain the diagonal of the transformed parallelogram. We can imagine the bottom of the parallelogram as new x-axis while left side of the parallelogram as the new y-axis. Each small parallelgram (which is transformation of each former square) is now a **unit** in this new co-ordinate system. The diagonal's far end is still located 3 units away from new y-axis and 4 units away from x-axis. Thus the vector $ \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} $ still representing the same diagonal, but according to the new system.  \n",
    "\n",
    "\n",
    "Let's consider a transformation where the bottom-right corner of the square moves to $ \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} $ and top-left corner of the square moves to $ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "![image info](vector34x.png)\n",
    "\n",
    "\n",
    "Our goal is to find the new co-ordinates of the diagonal vector according to the old system. The bottom-right corner of the larger parallelogram would be located along the new x-axis, and can be obtained by scaling the bottom side of the smaller parallelogram whos one corner is the center ( This is basis vector $ \\hat i$). The scale factor would be 3, going along the new x-axis 3 times would land us at the point  $ 3 * \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 3 \\end{bmatrix} $. (we are now 3 small parallelograms away from the new y-axis as we moved along the new x-axis)Now we want to go to the top-right corner of the larger parallelogram to reach at the far end of our diagonal vector. We now need to move parallel to the new y-axis 4 times. $ \\begin{bmatrix} 6 \\\\ 3 \\end{bmatrix} + 4 * \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\end{bmatrix}$ We have moved 4 small parallelograms up, and we are at the upper-right corner of the larger parallelogram, i.e. at the far end of the diagonal vector. Thus $\\begin{bmatrix} 10 \\\\ 11 \\end{bmatrix}$ is the co-ordinate of the diagonal vector.    \n",
    "\n",
    "#### Note the essential scaling we did here:  \n",
    "\n",
    "$ 3 * \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} +  4 * \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\end{bmatrix} $  \n",
    "\n",
    "3 and 4 are the relative co-ordinates of the diagonal vector in both new and old systems  \n",
    "$\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} $ is where the bottom-right corner of the square lands after the transformation  \n",
    "$\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $ is where the top-left corner of the square lands after the transformation  \n",
    "\n",
    "This transformation is represented as matrix vector multiplication:\n",
    "\n",
    "$\\begin{bmatrix} 2 \\ 1 \\\\ 1 \\ 2 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} = 3 * \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} +  4 * \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 10 \\\\ 11 \\end{bmatrix}$  \n",
    "\n",
    "Generically we can now get co-ordinates of any transformed vector  $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ for any given transformation $ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} $  \n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = x * \\begin{bmatrix} a \\\\ b \\end{bmatrix} +  y * \\begin{bmatrix} c \\\\ d \\end{bmatrix} =  \\begin{bmatrix} xa \\\\ xb \\end{bmatrix} +   \\begin{bmatrix} yc \\\\ yd \\end{bmatrix}=\\begin{bmatrix} xa+yc \\\\ xb+yd \\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7c395-6ceb-4efe-8abb-adf9f810f3e3",
   "metadata": {},
   "source": [
    "### Matrix multiplication : Multiple successive transformations represented as a single transformation (composition)\n",
    "\n",
    "#### Matrix multiplication as tranformation of multiple vectors\n",
    "\n",
    "Matrix multiplication can also be thought of transformation of multiple vectors (represensted in the right matrix)  \n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} e \\ g \\ i \\ k \\\\ f \\ h \\ j \\ l \\end{bmatrix} $  \n",
    "\n",
    "For example above product can be thought of as transformation of 4 vectors. Where each vector in the left matrix represents the basis vector after transformation. \n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} = \\begin{bmatrix} ae+cf \\ ag+ch \\\\ be+df \\ bg+dh \\end{bmatrix}$   = $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$  \n",
    "\n",
    "The above product can be considered as transforming the vectors $\\begin{bmatrix} e \\\\ f \\end{bmatrix} $  and $\\begin{bmatrix} g \\\\ h \\end{bmatrix} $ with the transformation $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$ and the result of product $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$ can be considered as the transformed vectors $\\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $\\begin{bmatrix} r \\\\ s \\end{bmatrix}$ from $\\begin{bmatrix} e \\\\ f \\end{bmatrix} $  and $\\begin{bmatrix} g \\\\ h \\end{bmatrix} $ respectively.\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Now let's see how applying the composite transformation $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$ as defined above (numerically and as multiple vectors transformation) is same as applying the transformations $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ and then $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$ successively onto any vector.\n",
    "\n",
    "In other terms:\n",
    "- The successsive transformation is \n",
    "    - first transforming the original vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ with $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ and \n",
    "    - and then with $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$ transformation. Note any transformation matrix actually represents two vectors where the basis vectors would land after the transformation.\n",
    "    - Symbolically : $T_2.(T_1.V_0)$ = $T_2.V_1$ = $V_2$\n",
    "- The composite transformation is \n",
    "    - first transforming the vectors represented by the matrix $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ into result matrix $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$ That is transforming $ \\begin{bmatrix} e \\\\ f \\end{bmatrix}$ and $ \\begin{bmatrix} g \\\\ h \\end{bmatrix}$ respectively into $ \\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $ \\begin{bmatrix} r \\\\ s \\end{bmatrix}$ to obtain the resultant transformation\n",
    "    - and then applying the resultant transformation  $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$ onto the original vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$.\n",
    "    - Symbolically: $(T_2.T_1).V_0$ = $T_{21}.V_0$ = $V_2$\n",
    "\n",
    "Note that, in the below discussion we are showing the transformations of basis and the original vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$, in parallel. The transformations of basis vectors are steps in the composite transformation while the transformstions of the original vector are the steps in successive transformation.\n",
    "\n",
    "Let's look into the transformations closely:\n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$  \n",
    "\n",
    "Here we are applying transformation $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ on $ \\begin{bmatrix} x \\\\ y \\end{bmatrix} $ It will land $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ at some $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$. Then we are applying $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$ on the intermediate result vector $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$, and finally it will land onto $\\begin{bmatrix} x'' \\\\ y'' \\end{bmatrix}$  \n",
    "\n",
    " $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} x' \\\\ y' \\end{bmatrix} $  \n",
    " \n",
    " $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} x'' \\\\ y'' \\end{bmatrix} $  \n",
    " \n",
    "$\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} $ actually represents two vectors $\\begin{bmatrix} e \\\\ f \\end{bmatrix}$ and $\\begin{bmatrix} g \\\\ h \\end{bmatrix}$, where actually the basis vectors would respectively land after the first transformation.  \n",
    " \n",
    " \n",
    "With the transformation $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$,  \n",
    "\n",
    "The basis vectors $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ and $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ would get transformed to $\\begin{bmatrix} e \\\\ f \\end{bmatrix}$ and $\\begin{bmatrix} g \\\\ h \\end{bmatrix}$ respectively.  \n",
    "The vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ would get transformed to $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  \n",
    "\n",
    "Note that, the basis vectors and $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ have undergone the same transformation $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$.  \n",
    "Therefore their transformed counterparts should have the same relationship (Addition of scaled basis vectors, recall the rubber rectangle with $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ as diagonal).  \n",
    "$x * \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + y * \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$  \n",
    "$x * \\begin{bmatrix} e \\\\ f \\end{bmatrix} + y * \\begin{bmatrix} g \\\\ h \\end{bmatrix} = \\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  \n",
    "\n",
    "\n",
    "With next tansformation $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$,  \n",
    "\n",
    "The transformed basis vectors $\\begin{bmatrix} e \\\\ f \\end{bmatrix}$ and $\\begin{bmatrix} g \\\\ h \\end{bmatrix}$ would get transformed to $\\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $\\begin{bmatrix} r \\\\ s \\end{bmatrix}$ respectively, as we defined these vectors in the first step in the composite transformation definition above.\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} e \\\\ f \\end{bmatrix} = \\begin{bmatrix} p \\\\ q \\end{bmatrix}$  \n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} g \\\\ h \\end{bmatrix} = \\begin{bmatrix} r \\\\ s \\end{bmatrix}$  \n",
    "The vector $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ would get transformed to $\\begin{bmatrix} x'' \\\\ y'' \\end{bmatrix}$  \n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  \n",
    "\n",
    "Note that, all the vectors $\\begin{bmatrix} e \\\\ f \\end{bmatrix}$, $\\begin{bmatrix} g \\\\ h \\end{bmatrix}$ and $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ have undergone the same transformation $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$.  \n",
    "Therefore their transformed counterparts should have the same relationship.  \n",
    "$x * \\begin{bmatrix} e \\\\ f \\end{bmatrix} + y * \\begin{bmatrix} g \\\\ h \\end{bmatrix} = \\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  $$\\tag {1}$$\n",
    "$x * \\begin{bmatrix} p \\\\ q \\end{bmatrix} + y * \\begin{bmatrix} r \\\\ s \\end{bmatrix} = \\begin{bmatrix} x'' \\\\ y'' \\end{bmatrix}$ \n",
    "\n",
    "Now lets think reverse way, we know because of the transformations the basis vectors finally landed at $ \\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $ \\begin{bmatrix} r \\\\ s \\end{bmatrix}$ respectively (or  $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ got transformed to  $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$), but if we had applied the composite transformation $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix} $ directly to $ \\begin{bmatrix} x \\\\ y \\end{bmatrix} $, the transformation would have been:  \n",
    "\n",
    "$\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} $  \n",
    "$ = x * \\begin{bmatrix} p \\\\ q \\end{bmatrix} + y * \\begin{bmatrix} r \\\\ s \\end{bmatrix}$ $$\\tag{From (1) Above}$$ \n",
    "$ = \\begin{bmatrix} x'' \\\\ y'' \\end{bmatrix} $  \n",
    "\n",
    "Thus, this looks to be the same as the result of applying $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} $ and then $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} $ to $\\begin{bmatrix} x \\\\ y \\end{bmatrix} $  \n",
    "\n",
    "In Summary, the vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix} $ when transformed to a new transformed space, retains the same relationship with the transformed basis vectors, as it was before the transformation. Even after the second transformation, the double transformed vector has the same relationship with double transformed basis vectors, because all of three are transformed with the same second transformation. After the second transformation, the double transformed vector's co-ordinates relative to very original basis vectors can be obtained by applying the same relation to the double transformed basis vectors. In other words, applying the successive transformations is the same as applying the composite transformation of successive transformations, because of the relation between the vector and basis vectors is retained after any transformation.   \n",
    "\n",
    "Also note that the matrix multiplication we defined numerically has actually meaning. It is the transformation of the transformed (due to first transformation) basis vectors. The result gives us the final transformation of the basis vectors, which can be used directly to tranform any vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12eb1d-0ae7-49ad-858f-bc6a3b9a965a",
   "metadata": {},
   "source": [
    "### Determinant\n",
    "\n",
    "Determinant of a transformation is the ratio of the area enclosed by the transformed basis vectors to the area enclosed by the original basis vectors (which is one), therefore, it is simply the area enclosed by the transformed vectors.  \n",
    "\n",
    "Note as we had seen the Linear transformation section above, each unit square get's transformed to a parallelogram after applying the transformation. Each tranformed parallelogram in the output grid has exactly same shape and size because it is transformation of all exactly same size and shape unit squares in the input space.  \n",
    "\n",
    "Area of any figure in the input space is some unit squares, could be in fractions. As the input space is transformed to output space, the tranformed output figure occupies the same no. of unit parallelograms in the output space as it was occupying unit squares in the input space. Therefore the proportion in which the area of the figure changes after transformation is the same as the proportion of change in the area of each unit sqaure, that is the determinant.  \n",
    "\n",
    "Say a figure was occupying 6.345 unit squares in the input space, it would occupy 6.345 unit parallelograms in the output space. If each parallelogram has increased by proportion 3.234 than the original unit square in input space, the proportion by which the area of the figure is changes is :  \n",
    "\n",
    "$ \\frac{6.345*3.234}{6.345*1} = 3.234 $  \n",
    "\n",
    "In general:  \n",
    "\n",
    "\n",
    "$ \\frac{A*D}{A*1} = D $  \n",
    "where A is the area masured in unit squares/parallelgrams and D is the determinant.   \n",
    "\n",
    "In summary, determinant is the proportion of change in the area of **any** shape or figure after transformation.  \n",
    "\n",
    "Negative determinant is flipping the space, we are facing the other side of the plane if it were a sheet of a paper. The basis vectors change there relative positions. If $ \\hat{j} $ is left to $\\hat{i}$ , after a flipping transformation, $ \\hat{i} $ comes left to $ \\hat{j} $. Still the absolute value tells the proportion of change in the area.(https://www.youtube.com/watch?v=Ip3X9LOh2dk&t=300s)  \n",
    "\n",
    "\n",
    "#### Computation of determinant:  \n",
    "\n",
    "It is the area of transformed parallelogram.\n",
    "\n",
    "\n",
    "![image info](determinant.png)\n",
    "\n",
    "\n",
    "#### Linear dependency and zero determinant\n",
    "\n",
    "Consider following matrix $\\begin{bmatrix} a \\ na \\\\ b \\ nb \\end{bmatrix} $, note here that the second basis vector is scaled version of first basis vector.    \n",
    "\n",
    "Determinant of this matrix is a * nb - b * na = anb - anb = 0$\\tag{0 determinant}$  \n",
    "\n",
    "When we apply this (matrix as a)transformation to any vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$  \n",
    "\n",
    "$\\begin{bmatrix} a \\ na \\\\ b \\ nb \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$  \n",
    "\n",
    "$ = x * \\begin{bmatrix} a \\\\ b \\end{bmatrix} + y * \\begin{bmatrix} na \\\\ nb \\end{bmatrix} $  \n",
    "\n",
    "$ = x * \\begin{bmatrix} a \\\\ b \\end{bmatrix} + ny * \\begin{bmatrix} a \\\\ b \\end{bmatrix} $  \n",
    "\n",
    "$ = (x + ny)* \\begin{bmatrix} a \\\\ b \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "This is just scaling of $\\begin{bmatrix} a \\\\ b \\end{bmatrix}$ by the factor (x + ny), i.e. for any values of x and y (for any vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$) it is a scaled $\\begin{bmatrix} a \\\\ b \\end{bmatrix}$, i.e. all the transformed vectors would land on the same line. We say that all these vectors are linearly dependent, i.e. one vector can be obtained from another vector just by scaling and all are along the same line.  \n",
    "\n",
    "By all vectors we mean the basis vectors $\\begin{bmatrix}  1 \\\\ 0 \\end{bmatrix}$ and $\\begin{bmatrix}  0 \\\\ 1 \\end{bmatrix}$ as well would land on the same line. That means the area enclosed by the transformed basis vectors is 0, i.e. by definition of the determinant, the determinant is 0; which we just saw in (0 determinant) above.  \n",
    "\n",
    "The reverse proof of this fact (i.e. if determinant is 0 then the basis vectors are linearly dependent) is as follows: \n",
    "\n",
    "\n",
    "$ det(\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}) = 0 $  \n",
    "\n",
    "a * d - b * c = 0  \n",
    "\n",
    "ad = bc  \n",
    "\n",
    "$\\frac{c}{a} = \\frac{d}{b}$  \n",
    "\n",
    "Let's say:\n",
    "\n",
    "$\\frac{c}{a} = \\frac{d}{b} = n $    \n",
    "\n",
    "Then,  \n",
    "\n",
    "$ c = na $ and $ d = nb $  \n",
    "\n",
    "$ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} = \\begin{bmatrix} a \\ na \\\\ b \\ nb \\end{bmatrix}$  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b911adb-be4e-44fd-b448-04958831c96f",
   "metadata": {},
   "source": [
    "### Inverse\n",
    "\n",
    "if $A \\vec{v} = \\vec{v'}$  \n",
    "\n",
    "then $A^{-1} \\vec{v'} = \\vec{v}$  \n",
    "\n",
    "$A^{-1}A=I$  \n",
    "\n",
    "Applying transformation $A$ on any vector $\\vec{v}$ and then again applying transformation $A^{-1}$ on the transformed vector  $\\vec{v'}$ gets the transformed vector back to the original vector  $\\vec{v}$. The matrix multiplication or composition is identity matrix $I$. Identitity matrix is a transformation which keeps any vector to the same position, like not at all applying the transformstion. The basis vectors in identity matrix are actually unit vectors in the input space.  \n",
    "\n",
    "#### Calculating inverse:(There could be better methods, this is just one simple method):  \n",
    "\n",
    "Let's calculate $ \\begin{bmatrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{bmatrix}$  \n",
    "\n",
    "By definition:  \n",
    "\n",
    "$\\begin{bmatrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{bmatrix}^{-1} \\begin{bmatrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 \\ 0 \\\\ 0 \\ 1 \\end{bmatrix}$  \n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix} \\begin{bmatrix} 1 \\ 1 \\\\ 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 \\ 0 \\\\ 0 \\ 1 \\end{bmatrix}$  \n",
    "\n",
    "$\\begin{bmatrix} a+c \\ a+2c \\\\ b+d \\ b+2d \\end{bmatrix} = \\begin{bmatrix} 1 \\ 0 \\\\ 0 \\ 1 \\end{bmatrix}$  \n",
    "\n",
    "Follows 4 equetions : \n",
    "\n",
    "$ a+c = 1 $  \n",
    "$ a+2c = 0 $  \n",
    "$ b+d = 0 $  \n",
    "$ b+2d = 1 $  \n",
    "\n",
    "Solving first two, a = 2 and c=-1 while, solving last two, b=-1 and d=1\n",
    "\n",
    "The inverse is $\\begin{bmatrix} 2 \\ -1 \\\\ -1 \\ 1 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "#### Inverse does not exists\n",
    "\n",
    "As we have seen in \"Linear dependency and zero determinant\", for a matrix with 0 determinant value, \n",
    "\n",
    "$\\begin{bmatrix} a \\ na \\\\ b \\ nb \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$  \n",
    "\n",
    "$ = (x + ny)* \\begin{bmatrix} a \\\\ b \\end{bmatrix} = \\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  \n",
    "\n",
    "How many ways can we obtain the same $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ as the result?  \n",
    "\n",
    "If we look at the above equation, a,b and n are parts of the transformation matrix. Only x,y are parts of the input vector.  \n",
    "\n",
    "Let's take a concrete example, where n is 3 and the input vector is $\\begin{bmatrix} 8 \\\\ 4 \\end{bmatrix}$  \n",
    "\n",
    "Then, $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = (8 + 4*3)\\begin{bmatrix} a \\\\ b \\end{bmatrix} = 20\\begin{bmatrix} a \\\\ b \\end{bmatrix}$  \n",
    "\n",
    "For another input vector, $\\begin{bmatrix} 5 \\\\ 5 \\end{bmatrix}$  \n",
    "\n",
    "$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = (5 + 5*3)\\begin{bmatrix} a \\\\ b \\end{bmatrix} = 20\\begin{bmatrix} a \\\\ b \\end{bmatrix}$  \n",
    "\n",
    "For another vectors $\\begin{bmatrix} 2 \\\\ 6 \\end{bmatrix}$, $\\begin{bmatrix} -1 \\\\ 7 \\end{bmatrix}$, $\\begin{bmatrix} 19.31 \\\\ 0.23 \\end{bmatrix}$  \n",
    "\n",
    "$\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = 20\\begin{bmatrix} a \\\\ b \\end{bmatrix}$  \n",
    "\n",
    "And then there are infinite number of other vectors the transformation lands them onto $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$  \n",
    "\n",
    "All the vectors having their endpoints on the line x+3y = 20, land onto $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ after transformation.  \n",
    "\n",
    "So which one of them is the original vector we started with?  \n",
    "\n",
    "You cannot have a function which maps the $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ to a single input vector, i.e. the inverse function does not exists for such a transformation. Note: In mathematics, a function from a set X to a set Y assigns to each element of X **exactly one** element of Y  \n",
    "\n",
    "\n",
    "![no_inverse](no_inverse.png)\n",
    "\n",
    "\n",
    "#### A special case for inverse\n",
    "\n",
    "If the vectors in a transformation are linearly dependent, but at the same time the vector to be transformed also lies on the same line as that of the vectors, then there exists only a single inverse vector (though there could be multiple inverse transfomrations exist). The pair of vectors $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ and $\\begin{bmatrix} x' \\\\ y' \\end{bmatrix}$ is unique. Basically, all the vectors (transformation and transformed) though in 2D space, can be represented on a single line, that is as 1D vectors, and therefore the transformation is kind of scaling and therefore the inverse scale factor can be calculated $ inverse(3) = \\frac{1}{3} $.\n",
    "\n",
    "As all the vectors involved now are linearly dependent:\n",
    "\n",
    "$\\begin{bmatrix} ma \\ na \\\\ mb \\ nb  \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\end{bmatrix} $\n",
    "\n",
    "$ = a \\begin{bmatrix} ma \\\\ mb \\end{bmatrix} + b \\begin{bmatrix} na \\\\ nb \\end{bmatrix}$\n",
    "\n",
    "$ = ma \\begin{bmatrix} a \\\\ b \\end{bmatrix} + nb \\begin{bmatrix} a \\\\ b \\end{bmatrix}$ \n",
    "\n",
    "$ = (ma + nb) \\begin{bmatrix} a \\\\ b \\end{bmatrix} $\n",
    "\n",
    "We can see that the transformed vector is scaled $\\begin{bmatrix} a \\\\ b \\end{bmatrix}$ with scale factor (ma + nb). \n",
    "\n",
    "$ \\begin{bmatrix} 1 \\ 2 \\\\ 2 \\ 4  \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix} = (1+4) \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix}  = 5\\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix} = \\begin{bmatrix} 15 \\\\ 30 \\end{bmatrix}$. \n",
    "\n",
    "The inverse vector can be found out by scaling the vector reverse (in this case scaling down).  \n",
    "\n",
    "$ \\frac{1}{(ma + nb)} \\begin{bmatrix} a \\\\ b \\end{bmatrix}$. \n",
    "\n",
    "$ \\frac{1}{5}\\begin{bmatrix} 15 \\\\ 30 \\end{bmatrix} =  \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea637aeb-c6e5-4f6f-b54f-25096dcf34e1",
   "metadata": {},
   "source": [
    "## Transformation between dimensions : Non square matrix\n",
    "\n",
    "#### 2D to 3D\n",
    "\n",
    "$\\begin{bmatrix} 1 \\ 1 \\\\ 0 \\ 1 \\\\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1  \\end{bmatrix} $  \n",
    "$\\begin{bmatrix} 1 \\ 1 \\\\ 0 \\ 1 \\\\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0  \\end{bmatrix} $  \n",
    "\n",
    "Basis vectors land into 3D space as described in the above non-square matrix.  \n",
    "\n",
    "Note that all the transformed vectors from 2D space land onto the output 3D space onto the same plane where the basis vectors land. (i.e. the plane containing the origin, and the endpoints of the vectors), because the two basis vectors form a plane, any linear combination of those two vectors remains on the same plane.    \n",
    "\n",
    "\n",
    "Below is the output 3D space, it is the top view of the plane containing all the transformed points. The thin blue line is the plane.\n",
    "\n",
    "![no_inverse](2d_vectors_on_3d_with_plane.png)\n",
    "\n",
    "![no_inverse](2d_vectors_on_3d.png)\n",
    "\n",
    "Below is the front view of the same plane, we can see the small parallelograms (DAHE,EHJF,ABIH etc) created by adjacent 4 points.  \n",
    "\n",
    "\n",
    "![no_inverse](2d_vectors_on_3d_front_view.png)\n",
    "Note the $\\vec{DA} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1  \\end{bmatrix} $,$\\vec{DE} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0  \\end{bmatrix} $ and $\\vec{DI} = \\begin{bmatrix} 3 \\\\ 1 \\\\ 2  \\end{bmatrix} $  \n",
    "$ \\vec{DI} =  2 \\vec{DA} + 1 \\vec{DE}$, i.e. $ \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} $, as can be seen in above graph.  \n",
    "$\\begin{bmatrix} 1 \\ 1 \\\\ 0 \\ 1 \\\\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 1 \\\\ 2  \\end{bmatrix} $  \n",
    "\n",
    "Thus the transformed vector has the same relation with the new basis vectors as it had before transformation with the old basis vectors $ i.e. \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} $  \n",
    "\n",
    "#### 3D to 2D\n",
    "\n",
    "$\\begin{bmatrix} 1 \\ 0 \\ 1 \\\\ 1 \\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1  \\end{bmatrix} $  \n",
    "$\\begin{bmatrix} 1 \\ 0 \\ 1 \\\\ 1 \\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1  \\end{bmatrix} $  \n",
    "$\\begin{bmatrix} 1 \\ 0 \\ 1 \\\\ 1 \\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0  \\end{bmatrix} $  \n",
    "\n",
    "We can observe 3 basis vectors in the above transformation matrix. The output 2D space contains 3 basis vector (though one of them is redundant, because it be constructed from two others), each transformed vector would be represented as combination of these three basis vectors.  \n",
    "\n",
    "$\\begin{bmatrix} 1 \\ 0 \\ 1 \\\\ 1 \\ 1 \\ 0  \\end{bmatrix}  \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix} = 1\\begin{bmatrix} 1 \\\\ 1  \\end{bmatrix} +3\\begin{bmatrix} 0 \\\\ 1  \\end{bmatrix}+2\\begin{bmatrix} 1 \\\\ 0  \\end{bmatrix}$  \n",
    "\n",
    "#### 1D to 2d\n",
    "\n",
    "$\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\begin{bmatrix} 3 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix}$  \n",
    "\n",
    "It is just scaling of the basis vector in the output 2D space by the iD vector in input space. All the vectors in the input 1D space gets mapped on a same line in the output 2D space, like in the above example all the transformed vectors land onto the line, y=2x  \n",
    "\n",
    "\n",
    "#### 2D to 1D\n",
    "\n",
    "$\\begin{bmatrix} 3 \\ 2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}  = \\begin{bmatrix} 3 \\end{bmatrix} $  \n",
    "$\\begin{bmatrix} 3 \\ 2 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}  = \\begin{bmatrix} 2 \\end{bmatrix} $  \n",
    "\n",
    "We can observe 2 basis vectors in the above transformation matrix. The output 1D space contains 2 basis vector (though one of them is redundant, because it be constructed from the other), each transformed vector would be represented as combination of these two basis vectors.  \n",
    "\n",
    "$\\begin{bmatrix} 3 \\ 2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}  = \\begin{bmatrix} 3  \\end{bmatrix} \\begin{bmatrix} 1  \\end{bmatrix} +\\begin{bmatrix} 2  \\end{bmatrix} \\begin{bmatrix} 2  \\end{bmatrix} $  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d579e7-1f57-4266-b7d7-d4b688efc8bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca5eda7-5611-4ebd-a52d-1f715949c56f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a28c1c-8f59-4767-bedf-ae77ac174f78",
   "metadata": {},
   "source": [
    "\n",
    "## Follwing content is not needed\n",
    "\n",
    "#### Before first transformation\n",
    "\n",
    "![image info](beforeFirstTn.png)\n",
    " \n",
    " \n",
    "#### After first transformation\n",
    "\n",
    "\n",
    "Applying $ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}  $ on the intermediate basis vector $\\begin{bmatrix} e \\\\ f \\end{bmatrix}$ would land it on $ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}  \\begin{bmatrix} e \\\\ f \\end{bmatrix} = e \\begin{bmatrix} a \\\\ b \\end{bmatrix} + f \\begin{bmatrix} c \\\\ d \\end{bmatrix} = \\begin{bmatrix} ea+fc \\\\ eb+fd \\end{bmatrix}$  \n",
    "Applying $ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}  $ on the intermediate basis vector $\\begin{bmatrix} g \\\\ h \\end{bmatrix}$ would land it on $ \\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}  \\begin{bmatrix} g \\\\ h \\end{bmatrix} = g \\begin{bmatrix} a \\\\ b \\end{bmatrix} + h \\begin{bmatrix} c \\\\ d \\end{bmatrix} = \\begin{bmatrix} ga+hc \\\\ gb+hd \\end{bmatrix}$  \n",
    "\n",
    "Now we do have a new set of basis vectors representing the combined transformation : $\\begin{bmatrix} ea+fc \\ ga+hc \\\\ eb+fd \\ gb+hd \\end{bmatrix}$  \n",
    "\n",
    "\n",
    "$\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix} =\\begin{bmatrix} ea+fc \\ ga+hc \\\\ eb+fd \\ gb+hd \\end{bmatrix} =  \\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix} $  \n",
    "\n",
    "The final transformation of the vector $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ depends on finally where the basic vectors would land after all the transformations. Any vectors in the tranformed space can be located using these final basis vectors.    \n",
    "\n",
    "\n",
    "Applying transformation $\\begin{bmatrix} a \\ c \\\\ b \\ d \\end{bmatrix}$ on vectors $\\begin{bmatrix} e \\ g \\\\ f \\ h \\end{bmatrix}$ (This matrix also represents a transformation with basis vector position after transformation) would land them on say $\\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $ \\begin{bmatrix} r \\\\ s \\end{bmatrix}$ respectively.  \n",
    "\n",
    "Applying transformation $\\begin{bmatrix} p \\ r \\\\ q \\ s \\end{bmatrix}$ on  $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$ would land it relative to the basis vectors  $\\begin{bmatrix} p \\\\ q \\end{bmatrix}$ and $ \\begin{bmatrix} r \\\\ s \\end{bmatrix}$ i.e. $x * \\begin{bmatrix} p \\\\ q \\end{bmatrix}+ y* \\begin{bmatrix} r \\\\ s \\end{bmatrix}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08427d9f-6f60-4aa5-abc4-f78d50305390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
